{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Model\n",
    "\n",
    "The water quality model employs supervised machine learning techniques to classify water as potable (1) or not potable (0), making this a binary classification problem since the output variable is categorical. Supervised learning is a type of machine learning where the model is trained on labeled data. In this context, \"labeled data\" means that each training example is paired with an output label. The goal of the model is to learn the mapping from inputs to outputs based on the provided labels. \n",
    "\n",
    "## Data\n",
    "\n",
    "The data is stored in a CSV file located in the `data` folder under the name `water_potability.csv`. The first task involves performing Exploratory Data Analysis (EDA) to identify any discrepancies in the dataset, normalize the data, and visualize it effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:16:06.118240: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import modules needed\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
      "0        NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
      "1   3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
      "2   8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
      "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
      "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
      "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
      "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
      "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
      "8        NaN  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
      "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "0       10.379783        86.990970   2.963135           0  \n",
      "1       15.180013        56.329076   4.500656           0  \n",
      "2       16.868637        66.420093   3.055934           0  \n",
      "3       18.436524       100.341674   4.628771           0  \n",
      "4       11.558279        31.997993   4.075075           0  \n",
      "5        8.399735        54.917862   2.559708           0  \n",
      "6       13.789695        84.603556   2.672989           0  \n",
      "7       12.363817        62.798309   4.401425           0  \n",
      "8       12.706049        53.928846   3.595017           0  \n",
      "9       17.927806        71.976601   4.370562           0  \n",
      "Data has 3276 rows and 10 columns\n"
     ]
    }
   ],
   "source": [
    "# read csv file and print the first 10 rows\n",
    "\n",
    "data = pd.read_csv('data/water_potability.csv')\n",
    "print(data.head(10))\n",
    "\n",
    "# Number of rows and columns in entire dataset\n",
    "print(f'Data has {data.shape[0]} rows and {data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for the availability and number of NaN values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan Values in each column: ph                 491\n",
      "Hardness             0\n",
      "Solids               0\n",
      "Chloramines          0\n",
      "Sulfate            781\n",
      "Conductivity         0\n",
      "Organic_carbon       0\n",
      "Trihalomethanes    162\n",
      "Turbidity            0\n",
      "Potability           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for Nan Values in each column\n",
    "nan_counts = data.isnull().sum()\n",
    "\n",
    "print(f'Nan Values in each column: {nan_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above the columns sulfate and Trihalomethanes both have a good number of NaN Values. \n",
    "\n",
    "### Replace NaN values with the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after replacement:\n",
      "ph                 0\n",
      "Hardness           0\n",
      "Solids             0\n",
      "Chloramines        0\n",
      "Sulfate            0\n",
      "Conductivity       0\n",
      "Organic_carbon     0\n",
      "Trihalomethanes    0\n",
      "Turbidity          0\n",
      "Potability         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values in 'sulfate' and 'Trihalomethanes' with the mean of the respective column\n",
    "data['ph'] = data['ph'].fillna(data['ph'].mean())\n",
    "data['Sulfate'] = data['Sulfate'].fillna(data['Sulfate'].mean())\n",
    "data['Trihalomethanes'] = data['Trihalomethanes'].fillna(data['Trihalomethanes'].mean())\n",
    "\n",
    "print(\"NaN values after replacement:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
      "0   7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
      "1   3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
      "2   8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
      "3   8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
      "4   9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
      "5   5.584087  188.313324  28748.687739     7.544869  326.678363    280.467916   \n",
      "6  10.223862  248.071735  28749.716544     7.513408  393.663396    283.651634   \n",
      "7   8.635849  203.361523  13672.091764     4.563009  303.309771    474.607645   \n",
      "8   7.080795  118.988579  14285.583854     7.804174  268.646941    389.375566   \n",
      "9  11.180284  227.231469  25484.508491     9.077200  404.041635    563.885481   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "0       10.379783        86.990970   2.963135           0  \n",
      "1       15.180013        56.329076   4.500656           0  \n",
      "2       16.868637        66.420093   3.055934           0  \n",
      "3       18.436524       100.341674   4.628771           0  \n",
      "4       11.558279        31.997993   4.075075           0  \n",
      "5        8.399735        54.917862   2.559708           0  \n",
      "6       13.789695        84.603556   2.672989           0  \n",
      "7       12.363817        62.798309   4.401425           0  \n",
      "8       12.706049        53.928846   3.595017           0  \n",
      "9       17.927806        71.976601   4.370562           0  \n"
     ]
    }
   ],
   "source": [
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X features:          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
      "0  7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
      "1  3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
      "2  8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
      "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
      "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  \n",
      "0       10.379783        86.990970   2.963135  \n",
      "1       15.180013        56.329076   4.500656  \n",
      "2       16.868637        66.420093   3.055934  \n",
      "3       18.436524       100.341674   4.628771  \n",
      "4       11.558279        31.997993   4.075075  \n",
      "Y target: 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Potability, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate our data to X -> Feature Columms and Y -> Output Label\n",
    "\n",
    "X = data.iloc[:, 0:9]\n",
    "Y = data['Potability']\n",
    "\n",
    "# Display first few rows of X and Y to verify\n",
    "print(f'X features: {X.head()}')\n",
    "print(f'Y target: {Y.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Data\n",
    "\n",
    "`Why Normalize?`\n",
    "\n",
    "- Consistent Scale: Ensures all features contribute equally to the model.\n",
    "- Improved Performance: Helps gradient-based algorithms converge faster.\n",
    "-Prevent Bias: Avoids models being biased towards features with larger scales.\n",
    "\n",
    "`Why Standard Scaler?`\n",
    "\n",
    "- Standardization: Transforms features to have a mean of 0 and a standard deviation of 1.\n",
    "- Robust to Different Ranges: Handles features with varying ranges effectively.\n",
    "- Suitable for Normal Distribution: Aligns well with algorithms assuming normally distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "def normalize_data(X):\n",
    "    '''\n",
    "    Normalizes a data\n",
    "    '''\n",
    "    normalized_data = scaler.fit_transform(X)\n",
    "    \n",
    "    return normalized_data \n",
    "\n",
    "X_normalized = normalize_data(X)\n",
    "print(type(X_normalized))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_normalized\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network for Binary Classification using tensorflow\n",
    "\n",
    "In the next cell, we define a function neural_net that constructs and compiles a neural network model using the TensorFlow Keras API. The function takes an optional parameter regularizer, which allows us to apply regularization to the Dense layers in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "def neural_net(regularizer=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (9,)),\n",
    "        tf.keras.layers.Dense(250, activation=\"tanh\", kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(125, activation=\"tanh\", kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "    ])\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer = 'adam',\n",
    "              loss = loss_function,\n",
    "              metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "unregularized_model = neural_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the training data to the Unregularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5730 - loss: 0.7077 - val_accuracy: 0.5604 - val_loss: 0.7136\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5970 - loss: 0.6876 - val_accuracy: 0.5885 - val_loss: 0.7022\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6155 - loss: 0.6626 - val_accuracy: 0.5690 - val_loss: 0.6992\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 0.6617 - val_accuracy: 0.5824 - val_loss: 0.6796\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6203 - loss: 0.6639 - val_accuracy: 0.5995 - val_loss: 0.6717\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6498 - loss: 0.6390 - val_accuracy: 0.6313 - val_loss: 0.6521\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6604 - loss: 0.6358 - val_accuracy: 0.6374 - val_loss: 0.6518\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.6217 - val_accuracy: 0.6422 - val_loss: 0.6265\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.6041 - val_accuracy: 0.6593 - val_loss: 0.6221\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6888 - loss: 0.5993 - val_accuracy: 0.6545 - val_loss: 0.6230\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.5975 - val_accuracy: 0.6654 - val_loss: 0.6131\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6929 - loss: 0.5844 - val_accuracy: 0.6654 - val_loss: 0.6200\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7081 - loss: 0.5820 - val_accuracy: 0.6496 - val_loss: 0.6275\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.5698 - val_accuracy: 0.6508 - val_loss: 0.6195\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.5766 - val_accuracy: 0.6728 - val_loss: 0.6176\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7036 - loss: 0.5799 - val_accuracy: 0.6606 - val_loss: 0.6253\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.5854 - val_accuracy: 0.6679 - val_loss: 0.6148\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.5759 - val_accuracy: 0.6581 - val_loss: 0.6182\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5567 - val_accuracy: 0.6557 - val_loss: 0.6141\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.5562 - val_accuracy: 0.6569 - val_loss: 0.6360\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.5753 - val_accuracy: 0.6618 - val_loss: 0.6208\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.5562 - val_accuracy: 0.6569 - val_loss: 0.6350\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5470 - val_accuracy: 0.6581 - val_loss: 0.6260\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5457 - val_accuracy: 0.6520 - val_loss: 0.6242\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.5387 - val_accuracy: 0.6581 - val_loss: 0.6264\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5351 - val_accuracy: 0.6667 - val_loss: 0.6304\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.5337 - val_accuracy: 0.6667 - val_loss: 0.6311\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7481 - loss: 0.5230 - val_accuracy: 0.6557 - val_loss: 0.6388\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5407 - val_accuracy: 0.6618 - val_loss: 0.6340\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7557 - loss: 0.5229 - val_accuracy: 0.6557 - val_loss: 0.6379\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.5266 - val_accuracy: 0.6569 - val_loss: 0.6328\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.5132 - val_accuracy: 0.6532 - val_loss: 0.6459\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.5136 - val_accuracy: 0.6569 - val_loss: 0.6573\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.5041 - val_accuracy: 0.6581 - val_loss: 0.6473\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7493 - loss: 0.4992 - val_accuracy: 0.6581 - val_loss: 0.6489\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7612 - loss: 0.4923 - val_accuracy: 0.6557 - val_loss: 0.6522\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7592 - loss: 0.4925 - val_accuracy: 0.6642 - val_loss: 0.6600\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.4998 - val_accuracy: 0.6569 - val_loss: 0.6599\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.4831 - val_accuracy: 0.6557 - val_loss: 0.6696\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7534 - loss: 0.4857 - val_accuracy: 0.6520 - val_loss: 0.6706\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.4983 - val_accuracy: 0.6569 - val_loss: 0.6750\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.4809 - val_accuracy: 0.6520 - val_loss: 0.6602\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.4705 - val_accuracy: 0.6532 - val_loss: 0.6705\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.4687 - val_accuracy: 0.6581 - val_loss: 0.6804\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.4518 - val_accuracy: 0.6569 - val_loss: 0.6772\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4518 - val_accuracy: 0.6618 - val_loss: 0.6997\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.4453 - val_accuracy: 0.6484 - val_loss: 0.6776\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7830 - loss: 0.4576 - val_accuracy: 0.6532 - val_loss: 0.7204\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7879 - loss: 0.4433 - val_accuracy: 0.6484 - val_loss: 0.6944\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4274 - val_accuracy: 0.6386 - val_loss: 0.6992\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.4205 - val_accuracy: 0.6459 - val_loss: 0.7025\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8107 - loss: 0.4219 - val_accuracy: 0.6508 - val_loss: 0.7095\n",
      "Epoch 53/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7994 - loss: 0.4283 - val_accuracy: 0.6508 - val_loss: 0.7215\n",
      "Epoch 54/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4313 - val_accuracy: 0.6459 - val_loss: 0.7127\n",
      "Epoch 55/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.3993 - val_accuracy: 0.6386 - val_loss: 0.7169\n",
      "Epoch 56/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.3886 - val_accuracy: 0.6435 - val_loss: 0.7270\n",
      "Epoch 57/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3844 - val_accuracy: 0.6374 - val_loss: 0.7293\n",
      "Epoch 58/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3803 - val_accuracy: 0.6471 - val_loss: 0.7446\n",
      "Epoch 59/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.3930 - val_accuracy: 0.6484 - val_loss: 0.7416\n",
      "Epoch 60/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8371 - loss: 0.3763 - val_accuracy: 0.6459 - val_loss: 0.7417\n",
      "Epoch 61/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.3839 - val_accuracy: 0.6361 - val_loss: 0.7462\n",
      "Epoch 62/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.3692 - val_accuracy: 0.6398 - val_loss: 0.7639\n",
      "Epoch 63/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3808 - val_accuracy: 0.6532 - val_loss: 0.7500\n",
      "Epoch 64/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.3528 - val_accuracy: 0.6508 - val_loss: 0.7578\n",
      "Epoch 65/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.3572 - val_accuracy: 0.6557 - val_loss: 0.7618\n",
      "Epoch 66/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.3355 - val_accuracy: 0.6398 - val_loss: 0.7673\n",
      "Epoch 67/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3267 - val_accuracy: 0.6447 - val_loss: 0.7655\n",
      "Epoch 68/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3261 - val_accuracy: 0.6386 - val_loss: 0.7717\n",
      "Epoch 69/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3400 - val_accuracy: 0.6398 - val_loss: 0.7916\n",
      "Epoch 70/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.3210 - val_accuracy: 0.6337 - val_loss: 0.7867\n",
      "Epoch 71/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.3294 - val_accuracy: 0.6325 - val_loss: 0.7910\n",
      "Epoch 72/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.3141 - val_accuracy: 0.6422 - val_loss: 0.7846\n",
      "Epoch 73/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3135 - val_accuracy: 0.6361 - val_loss: 0.7931\n",
      "Epoch 74/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.3104 - val_accuracy: 0.6288 - val_loss: 0.8003\n",
      "Epoch 75/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2985 - val_accuracy: 0.6337 - val_loss: 0.8271\n",
      "Epoch 76/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.2919 - val_accuracy: 0.6471 - val_loss: 0.8148\n",
      "Epoch 77/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.2944 - val_accuracy: 0.6300 - val_loss: 0.8215\n",
      "Epoch 78/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2840 - val_accuracy: 0.6374 - val_loss: 0.8173\n",
      "Epoch 79/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.2653 - val_accuracy: 0.6361 - val_loss: 0.8246\n",
      "Epoch 80/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.2719 - val_accuracy: 0.6276 - val_loss: 0.8294\n",
      "Epoch 81/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2660 - val_accuracy: 0.6386 - val_loss: 0.8402\n",
      "Epoch 82/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2635 - val_accuracy: 0.6337 - val_loss: 0.8614\n",
      "Epoch 83/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2666 - val_accuracy: 0.6288 - val_loss: 0.8565\n",
      "Epoch 84/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2578 - val_accuracy: 0.6337 - val_loss: 0.8604\n",
      "Epoch 85/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2522 - val_accuracy: 0.6264 - val_loss: 0.8619\n",
      "Epoch 86/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2498 - val_accuracy: 0.6300 - val_loss: 0.8757\n",
      "Epoch 87/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2541 - val_accuracy: 0.6435 - val_loss: 0.8932\n",
      "Epoch 88/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2385 - val_accuracy: 0.6313 - val_loss: 0.8824\n",
      "Epoch 89/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2363 - val_accuracy: 0.6447 - val_loss: 0.8896\n",
      "Epoch 90/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2226 - val_accuracy: 0.6288 - val_loss: 0.8846\n",
      "Epoch 91/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2172 - val_accuracy: 0.6178 - val_loss: 0.8936\n",
      "Epoch 92/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2144 - val_accuracy: 0.6239 - val_loss: 0.8998\n",
      "Epoch 93/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2254 - val_accuracy: 0.6288 - val_loss: 0.9069\n",
      "Epoch 94/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2086 - val_accuracy: 0.6361 - val_loss: 0.9119\n",
      "Epoch 95/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.2001 - val_accuracy: 0.6264 - val_loss: 0.9179\n",
      "Epoch 96/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1944 - val_accuracy: 0.6300 - val_loss: 0.9246\n",
      "Epoch 97/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2056 - val_accuracy: 0.6215 - val_loss: 0.9384\n",
      "Epoch 98/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1873 - val_accuracy: 0.6288 - val_loss: 0.9431\n",
      "Epoch 99/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1889 - val_accuracy: 0.6300 - val_loss: 0.9344\n",
      "Epoch 100/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1822 - val_accuracy: 0.6129 - val_loss: 0.9544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x145561e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unregularized_model.fit(X_train, Y_train, epochs = 100, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5976 - loss: 0.9520 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [656, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m y_true \u001b[38;5;241m=\u001b[39m Y_test\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m unregularized_model\u001b[38;5;241m.\u001b[39mevaluate(X_test, Y_test)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    225\u001b[0m     {\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [656, 2]"
     ]
    }
   ],
   "source": [
    "# confussion matrix with sklearn\n",
    "# import the module\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = Y_test\n",
    "y_pred = unregularized_model.evaluate(X_test, Y_test)\n",
    "\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a regularized model that uses L2 Regularization and train the model with X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5440 - loss: 0.7327 - val_accuracy: 0.5531 - val_loss: 0.7372\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.7069 - val_accuracy: 0.5665 - val_loss: 0.7197\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 0.6947 - val_accuracy: 0.5995 - val_loss: 0.7052\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6304 - loss: 0.6833 - val_accuracy: 0.5861 - val_loss: 0.6902\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6128 - loss: 0.6802 - val_accuracy: 0.5971 - val_loss: 0.6978\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6325 - loss: 0.6738 - val_accuracy: 0.6142 - val_loss: 0.6826\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6565 - loss: 0.6537 - val_accuracy: 0.6349 - val_loss: 0.6513\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6801 - loss: 0.6346 - val_accuracy: 0.6471 - val_loss: 0.6490\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.6176 - val_accuracy: 0.6606 - val_loss: 0.6296\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6926 - loss: 0.6135 - val_accuracy: 0.6716 - val_loss: 0.6304\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.6191 - val_accuracy: 0.6654 - val_loss: 0.6251\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.6010 - val_accuracy: 0.6679 - val_loss: 0.6260\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 0.6072 - val_accuracy: 0.6471 - val_loss: 0.6406\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6775 - loss: 0.6142 - val_accuracy: 0.6642 - val_loss: 0.6289\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6917 - loss: 0.5973 - val_accuracy: 0.6593 - val_loss: 0.6259\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7050 - loss: 0.5865 - val_accuracy: 0.6520 - val_loss: 0.6295\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.5837 - val_accuracy: 0.6691 - val_loss: 0.6265\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.5893 - val_accuracy: 0.6618 - val_loss: 0.6339\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.5871 - val_accuracy: 0.6728 - val_loss: 0.6273\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.5851 - val_accuracy: 0.6630 - val_loss: 0.6261\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.5988 - val_accuracy: 0.6716 - val_loss: 0.6318\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.5708 - val_accuracy: 0.6545 - val_loss: 0.6255\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.5783 - val_accuracy: 0.6703 - val_loss: 0.6259\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.5659 - val_accuracy: 0.6520 - val_loss: 0.6305\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7085 - loss: 0.5741 - val_accuracy: 0.6557 - val_loss: 0.6568\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7127 - loss: 0.5860 - val_accuracy: 0.6630 - val_loss: 0.6355\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7128 - loss: 0.5726 - val_accuracy: 0.6532 - val_loss: 0.6331\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5570 - val_accuracy: 0.6691 - val_loss: 0.6381\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7191 - loss: 0.5620 - val_accuracy: 0.6545 - val_loss: 0.6358\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5647 - val_accuracy: 0.6471 - val_loss: 0.6397\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5453 - val_accuracy: 0.6667 - val_loss: 0.6337\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.5537 - val_accuracy: 0.6642 - val_loss: 0.6399\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.5516 - val_accuracy: 0.6545 - val_loss: 0.6359\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.5519 - val_accuracy: 0.6569 - val_loss: 0.6527\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7453 - loss: 0.5441 - val_accuracy: 0.6545 - val_loss: 0.6470\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5501 - val_accuracy: 0.6654 - val_loss: 0.6524\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5426 - val_accuracy: 0.6545 - val_loss: 0.6516\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7506 - loss: 0.5374 - val_accuracy: 0.6496 - val_loss: 0.6508\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.5462 - val_accuracy: 0.6545 - val_loss: 0.6516\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5400 - val_accuracy: 0.6618 - val_loss: 0.6643\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7414 - loss: 0.5309 - val_accuracy: 0.6618 - val_loss: 0.6626\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.5257 - val_accuracy: 0.6569 - val_loss: 0.6499\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.5219 - val_accuracy: 0.6691 - val_loss: 0.6627\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.5054 - val_accuracy: 0.6667 - val_loss: 0.6668\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.5012 - val_accuracy: 0.6606 - val_loss: 0.6596\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7542 - loss: 0.5235 - val_accuracy: 0.6484 - val_loss: 0.6666\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4936 - val_accuracy: 0.6422 - val_loss: 0.6681\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.4967 - val_accuracy: 0.6532 - val_loss: 0.6919\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4943 - val_accuracy: 0.6410 - val_loss: 0.6698\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.4954 - val_accuracy: 0.6496 - val_loss: 0.6728\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.5009 - val_accuracy: 0.6667 - val_loss: 0.6737\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7849 - loss: 0.4890 - val_accuracy: 0.6496 - val_loss: 0.6755\n",
      "Epoch 53/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7825 - loss: 0.4870 - val_accuracy: 0.6496 - val_loss: 0.6781\n",
      "Epoch 54/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4814 - val_accuracy: 0.6532 - val_loss: 0.6917\n",
      "Epoch 55/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7944 - loss: 0.4805 - val_accuracy: 0.6496 - val_loss: 0.7000\n",
      "Epoch 56/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7813 - loss: 0.4883 - val_accuracy: 0.6593 - val_loss: 0.6974\n",
      "Epoch 57/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7874 - loss: 0.4901 - val_accuracy: 0.6569 - val_loss: 0.6991\n",
      "Epoch 58/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.4772 - val_accuracy: 0.6447 - val_loss: 0.6958\n",
      "Epoch 59/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7884 - loss: 0.4725 - val_accuracy: 0.6545 - val_loss: 0.7131\n",
      "Epoch 60/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8052 - loss: 0.4636 - val_accuracy: 0.6508 - val_loss: 0.6985\n",
      "Epoch 61/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7930 - loss: 0.4650 - val_accuracy: 0.6557 - val_loss: 0.7049\n",
      "Epoch 62/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8011 - loss: 0.4601 - val_accuracy: 0.6606 - val_loss: 0.7107\n",
      "Epoch 63/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8127 - loss: 0.4553 - val_accuracy: 0.6508 - val_loss: 0.7147\n",
      "Epoch 64/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8038 - loss: 0.4494 - val_accuracy: 0.6667 - val_loss: 0.7236\n",
      "Epoch 65/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.4358 - val_accuracy: 0.6349 - val_loss: 0.7200\n",
      "Epoch 66/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8288 - loss: 0.4332 - val_accuracy: 0.6484 - val_loss: 0.7170\n",
      "Epoch 67/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8278 - loss: 0.4400 - val_accuracy: 0.6618 - val_loss: 0.7208\n",
      "Epoch 68/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8193 - loss: 0.4289 - val_accuracy: 0.6484 - val_loss: 0.7239\n",
      "Epoch 69/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8212 - loss: 0.4432 - val_accuracy: 0.6471 - val_loss: 0.7416\n",
      "Epoch 70/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.4134 - val_accuracy: 0.6520 - val_loss: 0.7304\n",
      "Epoch 71/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.4235 - val_accuracy: 0.6508 - val_loss: 0.7387\n",
      "Epoch 72/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.4261 - val_accuracy: 0.6410 - val_loss: 0.7405\n",
      "Epoch 73/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.4210 - val_accuracy: 0.6459 - val_loss: 0.7448\n",
      "Epoch 74/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8495 - loss: 0.4064 - val_accuracy: 0.6630 - val_loss: 0.7481\n",
      "Epoch 75/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.4163 - val_accuracy: 0.6618 - val_loss: 0.7532\n",
      "Epoch 76/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.3999 - val_accuracy: 0.6630 - val_loss: 0.7578\n",
      "Epoch 77/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.4121 - val_accuracy: 0.6435 - val_loss: 0.7570\n",
      "Epoch 78/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.4131 - val_accuracy: 0.6435 - val_loss: 0.7578\n",
      "Epoch 79/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8540 - loss: 0.3979 - val_accuracy: 0.6459 - val_loss: 0.7726\n",
      "Epoch 80/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.4097 - val_accuracy: 0.6459 - val_loss: 0.7895\n",
      "Epoch 81/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8404 - loss: 0.4062 - val_accuracy: 0.6545 - val_loss: 0.7782\n",
      "Epoch 82/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 0.3956 - val_accuracy: 0.6618 - val_loss: 0.7774\n",
      "Epoch 83/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8407 - loss: 0.3963 - val_accuracy: 0.6508 - val_loss: 0.7788\n",
      "Epoch 84/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8496 - loss: 0.3926 - val_accuracy: 0.6435 - val_loss: 0.8009\n",
      "Epoch 85/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3915 - val_accuracy: 0.6471 - val_loss: 0.7933\n",
      "Epoch 86/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8430 - loss: 0.3930 - val_accuracy: 0.6459 - val_loss: 0.7916\n",
      "Epoch 87/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3787 - val_accuracy: 0.6496 - val_loss: 0.8082\n",
      "Epoch 88/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3840 - val_accuracy: 0.6447 - val_loss: 0.7998\n",
      "Epoch 89/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8696 - loss: 0.3650 - val_accuracy: 0.6422 - val_loss: 0.7987\n",
      "Epoch 90/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3726 - val_accuracy: 0.6374 - val_loss: 0.8127\n",
      "Epoch 91/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3679 - val_accuracy: 0.6459 - val_loss: 0.8134\n",
      "Epoch 92/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3462 - val_accuracy: 0.6422 - val_loss: 0.8286\n",
      "Epoch 93/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.3643 - val_accuracy: 0.6508 - val_loss: 0.8406\n",
      "Epoch 94/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8927 - loss: 0.3394 - val_accuracy: 0.6459 - val_loss: 0.8247\n",
      "Epoch 95/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.3592 - val_accuracy: 0.6435 - val_loss: 0.8366\n",
      "Epoch 96/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3657 - val_accuracy: 0.6386 - val_loss: 0.8353\n",
      "Epoch 97/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3336 - val_accuracy: 0.6398 - val_loss: 0.8432\n",
      "Epoch 98/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8823 - loss: 0.3396 - val_accuracy: 0.6349 - val_loss: 0.8443\n",
      "Epoch 99/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8746 - loss: 0.3466 - val_accuracy: 0.6374 - val_loss: 0.8485\n",
      "Epoch 100/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8776 - loss: 0.3549 - val_accuracy: 0.6325 - val_loss: 0.8577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14e7f0230>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularizer = tf.keras.regularizers.l2(0.0001)\n",
    "reg_model = neural_net(regularizer)\n",
    "\n",
    "reg_model.fit(X_train, Y_train, epochs = 100, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Dropout in confluence with L2 Regularization\n",
    "\n",
    "Our model currently has an accuracy of 89.14% and a loss of 0.34 on the training data and 64.96% accuracy and a loss of 0.86, suggesting a possible case of `Overfitting`. Now let's try to implement early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5616 - loss: 0.7736 - val_accuracy: 0.5543 - val_loss: 0.7826\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6007 - loss: 0.7339 - val_accuracy: 0.5897 - val_loss: 0.7361\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6103 - loss: 0.7125 - val_accuracy: 0.5714 - val_loss: 0.7180\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6136 - loss: 0.7058 - val_accuracy: 0.6081 - val_loss: 0.7211\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6071 - loss: 0.7047 - val_accuracy: 0.6142 - val_loss: 0.7030\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6128 - loss: 0.6925 - val_accuracy: 0.6252 - val_loss: 0.6894\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6591 - loss: 0.6555 - val_accuracy: 0.6361 - val_loss: 0.6597\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6579 - loss: 0.6591 - val_accuracy: 0.6178 - val_loss: 0.6840\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.6322 - val_accuracy: 0.6691 - val_loss: 0.6488\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6870 - loss: 0.6279 - val_accuracy: 0.6569 - val_loss: 0.6477\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.6268 - val_accuracy: 0.6484 - val_loss: 0.6387\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.6209 - val_accuracy: 0.6703 - val_loss: 0.6328\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6805 - loss: 0.6138 - val_accuracy: 0.6667 - val_loss: 0.6306\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7109 - loss: 0.5991 - val_accuracy: 0.6581 - val_loss: 0.6371\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7055 - loss: 0.5971 - val_accuracy: 0.6630 - val_loss: 0.6240\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.5974 - val_accuracy: 0.6508 - val_loss: 0.6343\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7070 - loss: 0.5873 - val_accuracy: 0.6716 - val_loss: 0.6287\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7042 - loss: 0.5873 - val_accuracy: 0.6496 - val_loss: 0.6325\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7056 - loss: 0.5924 - val_accuracy: 0.6569 - val_loss: 0.6344\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7055 - loss: 0.5926 - val_accuracy: 0.6508 - val_loss: 0.6365\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6981 - loss: 0.5867 - val_accuracy: 0.6618 - val_loss: 0.6324\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.5767 - val_accuracy: 0.6581 - val_loss: 0.6313\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7157 - loss: 0.5687 - val_accuracy: 0.6569 - val_loss: 0.6280\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7152 - loss: 0.5719 - val_accuracy: 0.6471 - val_loss: 0.6399\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5692 - val_accuracy: 0.6557 - val_loss: 0.6425\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5563 - val_accuracy: 0.6569 - val_loss: 0.6354\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7090 - loss: 0.5740 - val_accuracy: 0.6520 - val_loss: 0.6427\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7245 - loss: 0.5665 - val_accuracy: 0.6496 - val_loss: 0.6476\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.5603 - val_accuracy: 0.6459 - val_loss: 0.6499\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5579 - val_accuracy: 0.6642 - val_loss: 0.6383\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.5533 - val_accuracy: 0.6606 - val_loss: 0.6387\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7476 - loss: 0.5412 - val_accuracy: 0.6398 - val_loss: 0.6570\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.5611 - val_accuracy: 0.6435 - val_loss: 0.6639\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5541 - val_accuracy: 0.6606 - val_loss: 0.6442\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7420 - loss: 0.5441 - val_accuracy: 0.6764 - val_loss: 0.6449\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.5422 - val_accuracy: 0.6459 - val_loss: 0.6565\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7404 - loss: 0.5391 - val_accuracy: 0.6532 - val_loss: 0.6787\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7332 - loss: 0.5542 - val_accuracy: 0.6581 - val_loss: 0.6473\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.5240 - val_accuracy: 0.6630 - val_loss: 0.6527\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.5418 - val_accuracy: 0.6593 - val_loss: 0.6556\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7625 - loss: 0.5181 - val_accuracy: 0.6496 - val_loss: 0.6864\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.5229 - val_accuracy: 0.6569 - val_loss: 0.6670\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7667 - loss: 0.5119 - val_accuracy: 0.6581 - val_loss: 0.6609\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.5383 - val_accuracy: 0.6716 - val_loss: 0.6702\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.5061 - val_accuracy: 0.6484 - val_loss: 0.6695\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7737 - loss: 0.5033 - val_accuracy: 0.6606 - val_loss: 0.6654\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7705 - loss: 0.5068 - val_accuracy: 0.6508 - val_loss: 0.6674\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - loss: 0.5129 - val_accuracy: 0.6679 - val_loss: 0.6731\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7653 - loss: 0.4991 - val_accuracy: 0.6484 - val_loss: 0.6652\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7847 - loss: 0.4895 - val_accuracy: 0.6716 - val_loss: 0.6850\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7696 - loss: 0.4964 - val_accuracy: 0.6618 - val_loss: 0.6714\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.4853 - val_accuracy: 0.6569 - val_loss: 0.6836\n",
      "Epoch 53/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.4894 - val_accuracy: 0.6667 - val_loss: 0.6905\n",
      "Epoch 54/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7711 - loss: 0.4976 - val_accuracy: 0.6606 - val_loss: 0.6975\n",
      "Epoch 55/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7925 - loss: 0.4819 - val_accuracy: 0.6630 - val_loss: 0.6915\n",
      "Epoch 56/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7914 - loss: 0.4704 - val_accuracy: 0.6630 - val_loss: 0.6894\n",
      "Epoch 57/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.4793 - val_accuracy: 0.6410 - val_loss: 0.6914\n",
      "Epoch 58/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7986 - loss: 0.4720 - val_accuracy: 0.6532 - val_loss: 0.7147\n",
      "Epoch 59/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7669 - loss: 0.4901 - val_accuracy: 0.6569 - val_loss: 0.7180\n",
      "Epoch 60/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.4717 - val_accuracy: 0.6459 - val_loss: 0.6931\n",
      "Epoch 61/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7942 - loss: 0.4759 - val_accuracy: 0.6532 - val_loss: 0.7078\n",
      "Epoch 62/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4598 - val_accuracy: 0.6459 - val_loss: 0.7223\n",
      "Epoch 63/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.4501 - val_accuracy: 0.6496 - val_loss: 0.7146\n",
      "Epoch 64/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 0.4760 - val_accuracy: 0.6545 - val_loss: 0.7257\n",
      "Epoch 65/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.4467 - val_accuracy: 0.6593 - val_loss: 0.7217\n",
      "Epoch 66/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8132 - loss: 0.4471 - val_accuracy: 0.6642 - val_loss: 0.7239\n",
      "Epoch 67/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.4352 - val_accuracy: 0.6459 - val_loss: 0.7339\n",
      "Epoch 68/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8126 - loss: 0.4373 - val_accuracy: 0.6447 - val_loss: 0.7518\n",
      "Epoch 69/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.4488 - val_accuracy: 0.6410 - val_loss: 0.7483\n",
      "Epoch 70/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4420 - val_accuracy: 0.6459 - val_loss: 0.7559\n",
      "Epoch 71/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.4335 - val_accuracy: 0.6593 - val_loss: 0.7532\n",
      "Epoch 72/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.4268 - val_accuracy: 0.6496 - val_loss: 0.7655\n",
      "Epoch 73/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.4297 - val_accuracy: 0.6581 - val_loss: 0.7585\n",
      "Epoch 74/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.4179 - val_accuracy: 0.6569 - val_loss: 0.7554\n",
      "Epoch 75/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.4229 - val_accuracy: 0.6496 - val_loss: 0.7718\n",
      "Epoch 76/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.4212 - val_accuracy: 0.6496 - val_loss: 0.7740\n",
      "Epoch 77/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.3992 - val_accuracy: 0.6691 - val_loss: 0.7644\n",
      "Epoch 78/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8444 - loss: 0.4079 - val_accuracy: 0.6398 - val_loss: 0.7743\n",
      "Epoch 79/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.4080 - val_accuracy: 0.6557 - val_loss: 0.7810\n",
      "Epoch 80/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.4087 - val_accuracy: 0.6593 - val_loss: 0.7753\n",
      "Epoch 81/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8297 - loss: 0.4284 - val_accuracy: 0.6496 - val_loss: 0.7870\n",
      "Epoch 82/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.4054 - val_accuracy: 0.6422 - val_loss: 0.7991\n",
      "Epoch 83/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: 0.3867 - val_accuracy: 0.6459 - val_loss: 0.8048\n",
      "Epoch 84/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.4020 - val_accuracy: 0.6410 - val_loss: 0.7983\n",
      "Epoch 85/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.4114 - val_accuracy: 0.6300 - val_loss: 0.7988\n",
      "Epoch 86/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.4070 - val_accuracy: 0.6545 - val_loss: 0.8057\n",
      "Epoch 87/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.4100 - val_accuracy: 0.6581 - val_loss: 0.7955\n",
      "Epoch 88/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 0.3982 - val_accuracy: 0.6459 - val_loss: 0.8165\n",
      "Epoch 89/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3793 - val_accuracy: 0.6459 - val_loss: 0.8214\n",
      "Epoch 90/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 0.3821 - val_accuracy: 0.6630 - val_loss: 0.8195\n",
      "Epoch 91/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 0.3843 - val_accuracy: 0.6496 - val_loss: 0.8094\n",
      "Epoch 92/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.3769 - val_accuracy: 0.6447 - val_loss: 0.8378\n",
      "Epoch 93/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3836 - val_accuracy: 0.6532 - val_loss: 0.8325\n",
      "Epoch 94/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.3665 - val_accuracy: 0.6569 - val_loss: 0.8415\n",
      "Epoch 95/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.3692 - val_accuracy: 0.6484 - val_loss: 0.8380\n",
      "Epoch 96/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.3638 - val_accuracy: 0.6496 - val_loss: 0.8372\n",
      "Epoch 97/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.3659 - val_accuracy: 0.6422 - val_loss: 0.8512\n",
      "Epoch 98/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.3697 - val_accuracy: 0.6435 - val_loss: 0.8561\n",
      "Epoch 99/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8821 - loss: 0.3406 - val_accuracy: 0.6508 - val_loss: 0.8576\n",
      "Epoch 100/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.3590 - val_accuracy: 0.6484 - val_loss: 0.8630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14f1dd730>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the neural network model with L2 regularization and Dropout\n",
    "def neural_net_with_dropout(regularizer=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(9,)),\n",
    "        tf.keras.layers.Dense(500, activation=\"tanh\", kernel_regularizer=regularizer),\n",
    "        # tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(250, activation=\"tanh\", kernel_regularizer=regularizer),\n",
    "        # tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "    ])\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_function,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "regularizer = tf.keras.regularizers.l2(0.0001)\n",
    "dropout_model = neural_net_with_dropout(regularizer)\n",
    "\n",
    "# Train the model with the EarlyStopping callback\n",
    "dropout_model.fit(\n",
    "    X_train, Y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_val, Y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
