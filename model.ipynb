{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Model\n",
    "\n",
    "The water quality model employs supervised machine learning techniques to classify water as potable (1) or not potable (0), making this a binary classification problem since the output variable is categorical. Supervised learning is a type of machine learning where the model is trained on labeled data. In this context, \"labeled data\" means that each training example is paired with an output label. The goal of the model is to learn the mapping from inputs to outputs based on the provided labels. \n",
    "\n",
    "## Data\n",
    "\n",
    "The data is stored in a CSV file located in the `data` folder under the name `water_potability.csv`. This dataset contains water quality measurements and assessments related to potability, which is the suitability of water for human consumption. The dataset's primary objective is to provide insights into water quality parameters and assist in determining whether the water is potable or not. Each row in the dataset represents a water sample with specific attributes, and the \"Potability\" column indicates whether the water is suitable for consumption.\n",
    "\n",
    "https://www.kaggle.com/datasets/uom190346a/water-quality-and-potability?select=water_potability.csv\n",
    "\n",
    "The first task involves performing Exploratory Data Analysis (EDA) to identify any discrepancies in the dataset, normalize the data, and visualize it effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules needed\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
      "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
      "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
      "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
      "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
      "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "0       10.379783        86.990970   2.963135           0  \n",
      "1       15.180013        56.329076   4.500656           0  \n",
      "2       16.868637        66.420093   3.055934           0  \n",
      "3       18.436524       100.341674   4.628771           0  \n",
      "4       11.558279        31.997993   4.075075           0  \n",
      "Data has 3276 rows and 10 columns\n"
     ]
    }
   ],
   "source": [
    "# read csv file and print the first 10 rows\n",
    "data = pd.read_csv('data/water_potability.csv')\n",
    "print(data.head(5))\n",
    "\n",
    "# Number of rows and columns in entire dataset\n",
    "print(f'Data has {data.shape[0]} rows and {data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for the availability and number of NaN values in the dataset\n",
    "\n",
    "## Why is it important\n",
    "There are two main reasons why checking for NaN (Not a Number) values is crucial during data preprocessing:\n",
    "\n",
    "Maintaining Model Stability: Many machine learning algorithms rely on mathematical operations that can't handle NaN values. For instance, dividing by a NaN value would result in an error or unexpected output. By identifying and addressing NaN values, you ensure the smooth operation of these algorithms and prevent errors during training and prediction.\n",
    "\n",
    "Preserving Data Integrity: NaN values represent missing data points. If left unchecked, they can skew your analysis and lead to inaccurate or misleading results.  Understanding the presence and distribution of NaN values allows you to make informed decisions about how to handle them. You might choose to remove rows with NaN values, impute them with estimated values, or create a separate category for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan Values in each column: ph                 491\n",
      "Hardness             0\n",
      "Solids               0\n",
      "Chloramines          0\n",
      "Sulfate            781\n",
      "Conductivity         0\n",
      "Organic_carbon       0\n",
      "Trihalomethanes    162\n",
      "Turbidity            0\n",
      "Potability           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for Nan Values in each column\n",
    "nan_counts = data.isnull().sum()\n",
    "\n",
    "print(f'Nan Values in each column: {nan_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above the columns ph, sulfate and Trihalomethanes both have a good number of NaN Values. \n",
    "\n",
    "### Replace NaN values with the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after replacement:\n",
      "ph                 0\n",
      "Hardness           0\n",
      "Solids             0\n",
      "Chloramines        0\n",
      "Sulfate            0\n",
      "Conductivity       0\n",
      "Organic_carbon     0\n",
      "Trihalomethanes    0\n",
      "Turbidity          0\n",
      "Potability         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values in 'sulfate' and 'Trihalomethanes' with the mean of the respective column\n",
    "data['ph'] = data['ph'].fillna(data['ph'].mean())\n",
    "data['Sulfate'] = data['Sulfate'].fillna(data['Sulfate'].mean())\n",
    "data['Trihalomethanes'] = data['Trihalomethanes'].fillna(data['Trihalomethanes'].mean())\n",
    "\n",
    "print(\"NaN values after replacement:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
      "0  7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
      "1  3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
      "2  8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
      "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
      "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "0       10.379783        86.990970   2.963135           0  \n",
      "1       15.180013        56.329076   4.500656           0  \n",
      "2       16.868637        66.420093   3.055934           0  \n",
      "3       18.436524       100.341674   4.628771           0  \n",
      "4       11.558279        31.997993   4.075075           0  \n"
     ]
    }
   ],
   "source": [
    "# Validate that the data has no NaN Values\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X features:          ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
      "0  7.080795  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
      "1  3.716080  129.422921  18630.057858     6.635246  333.775777    592.885359   \n",
      "2  8.099124  224.236259  19909.541732     9.275884  333.775777    418.606213   \n",
      "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
      "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  \n",
      "0       10.379783        86.990970   2.963135  \n",
      "1       15.180013        56.329076   4.500656  \n",
      "2       16.868637        66.420093   3.055934  \n",
      "3       18.436524       100.341674   4.628771  \n",
      "4       11.558279        31.997993   4.075075  \n",
      "Y target: 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Potability, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate our data to X -> Feature Columms and Y -> Output Label\n",
    "X = data.iloc[:, 0:9]\n",
    "Y = data['Potability']\n",
    "\n",
    "# Display first few rows of X and Y to verify\n",
    "print(f'X features: {X.head()}')\n",
    "print(f'Y target: {Y.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Data\n",
    "\n",
    "`Why Normalize?`\n",
    "\n",
    "- Consistent Scale: Ensures all features contribute equally to the model.\n",
    "- Improved Performance: Helps gradient-based algorithms converge faster.\n",
    "-Prevent Bias: Avoids models being biased towards features with larger scales.\n",
    "\n",
    "`Standard Scaler`\n",
    "\n",
    "Standard Scaler normalization is a technique used to transform the features of a dataset so that they have a mean of 0 and a standard deviation of 1. This is also known as standardization or Z-score normalization. Formula:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( z \\) is the standardized value.\n",
    "- \\( x \\) is the original value.\n",
    "- \\( \\mu \\) is the mean of the dataset.\n",
    "- \\( \\sigma \\) is the standard deviation of the dataset.\n",
    "\n",
    "`Why Standard Scaler?`\n",
    "\n",
    "- Standardization: Transforms features to have a mean of 0 and a standard deviation of 1.\n",
    "- Robust to Different Ranges: Handles features with varying ranges effectively.\n",
    "- Suitable for Normal Distribution: Aligns well with algorithms assuming normally distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[-6.04313345e-16  2.59194711e-01 -1.39470871e-01  1.12414846e-01\n",
      "   9.61357416e-01  1.70895423e+00 -1.18065057e+00  1.30614943e+00\n",
      "  -1.28629758e+00]\n",
      " [-2.28933938e+00 -2.03641367e+00 -3.85986650e-01 -3.07693708e-01\n",
      "   3.14598714e-15  2.06257500e+00  2.70597240e-01 -6.38479983e-01\n",
      "   6.84217891e-01]\n",
      " [ 6.92867789e-01  8.47664833e-01 -2.40047337e-01  1.36059386e+00\n",
      "   3.14598714e-15 -9.40321148e-02  7.81116857e-01  1.50940884e-03\n",
      "  -1.16736546e+00]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "def normalize_data(X):\n",
    "    '''\n",
    "    Normalizes a data\n",
    "    '''\n",
    "    normalized_data = scaler.fit_transform(X)\n",
    "    \n",
    "    return normalized_data \n",
    "\n",
    "X_normalized = normalize_data(X)\n",
    "print(type(X_normalized))\n",
    "print(X_normalized[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_normalized\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network for Binary Classification using tensorflow\n",
    "\n",
    "In the next cell, we define a function neural_net that constructs and compiles a neural network model using the TensorFlow Keras API. The function takes an optional parameter regularizer, which allows us to apply regularization to the Dense layers in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(regularizer=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (9,)),\n",
    "        tf.keras.layers.Dense(250, activation=\"relu\", kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(125, activation=\"relu\", kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "    ])\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer = 'adam',\n",
    "              loss = loss_function,\n",
    "              metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of our neural network with no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,375</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">252</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │         \u001b[38;5;34m2,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m)            │        \u001b[38;5;34m31,375\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m252\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,127</span> (133.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,127\u001b[0m (133.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,127</span> (133.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,127\u001b[0m (133.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unregularized_model = neural_net()\n",
    "unregularized_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the training data to the Unregularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6265 - loss: 0.6622 - val_accuracy: 0.6235 - val_loss: 0.6395\n",
      "Epoch 2/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6786 - loss: 0.6071 - val_accuracy: 0.6402 - val_loss: 0.6127\n",
      "Epoch 3/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.5877 - val_accuracy: 0.6585 - val_loss: 0.6050\n",
      "Epoch 4/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7027 - loss: 0.5791 - val_accuracy: 0.6479 - val_loss: 0.6120\n",
      "Epoch 5/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.5788 - val_accuracy: 0.6433 - val_loss: 0.6192\n",
      "Epoch 6/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.5677 - val_accuracy: 0.6601 - val_loss: 0.5986\n",
      "Epoch 7/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.5397 - val_accuracy: 0.6677 - val_loss: 0.6075\n",
      "Epoch 8/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7251 - loss: 0.5457 - val_accuracy: 0.6753 - val_loss: 0.6130\n",
      "Epoch 9/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.5385 - val_accuracy: 0.6601 - val_loss: 0.6309\n",
      "Epoch 10/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5373 - val_accuracy: 0.6662 - val_loss: 0.6064\n",
      "Epoch 11/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.5201 - val_accuracy: 0.6357 - val_loss: 0.6274\n",
      "Epoch 12/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.5145 - val_accuracy: 0.6494 - val_loss: 0.6208\n",
      "Epoch 13/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7593 - loss: 0.5037 - val_accuracy: 0.6768 - val_loss: 0.6119\n",
      "Epoch 14/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.4937 - val_accuracy: 0.6723 - val_loss: 0.6344\n",
      "Epoch 15/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7783 - loss: 0.4828 - val_accuracy: 0.6570 - val_loss: 0.6288\n",
      "Epoch 16/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.4779 - val_accuracy: 0.6601 - val_loss: 0.6107\n",
      "Epoch 17/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7893 - loss: 0.4567 - val_accuracy: 0.6905 - val_loss: 0.6032\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.4590 - val_accuracy: 0.6692 - val_loss: 0.6353\n",
      "Epoch 19/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.4292 - val_accuracy: 0.6662 - val_loss: 0.6301\n",
      "Epoch 20/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.4404 - val_accuracy: 0.6799 - val_loss: 0.6452\n",
      "Epoch 21/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4219 - val_accuracy: 0.6677 - val_loss: 0.6464\n",
      "Epoch 22/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - loss: 0.4012 - val_accuracy: 0.6860 - val_loss: 0.6471\n",
      "Epoch 23/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8140 - loss: 0.4007 - val_accuracy: 0.6738 - val_loss: 0.6721\n",
      "Epoch 24/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3880 - val_accuracy: 0.6631 - val_loss: 0.6495\n",
      "Epoch 25/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3839 - val_accuracy: 0.6616 - val_loss: 0.6466\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.3563 - val_accuracy: 0.6814 - val_loss: 0.6417\n",
      "Epoch 27/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3485 - val_accuracy: 0.6814 - val_loss: 0.6737\n",
      "Epoch 28/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3354 - val_accuracy: 0.6555 - val_loss: 0.6976\n",
      "Epoch 29/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.3109 - val_accuracy: 0.6723 - val_loss: 0.6804\n",
      "Epoch 30/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.3237 - val_accuracy: 0.6387 - val_loss: 0.7226\n",
      "Epoch 31/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.3105 - val_accuracy: 0.6616 - val_loss: 0.7481\n",
      "Epoch 32/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.3063 - val_accuracy: 0.6555 - val_loss: 0.7333\n",
      "Epoch 33/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3008 - val_accuracy: 0.6555 - val_loss: 0.7383\n",
      "Epoch 34/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2865 - val_accuracy: 0.6616 - val_loss: 0.7381\n",
      "Epoch 35/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.2732 - val_accuracy: 0.6738 - val_loss: 0.7454\n",
      "Epoch 36/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2697 - val_accuracy: 0.6662 - val_loss: 0.8455\n",
      "Epoch 37/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.2528 - val_accuracy: 0.6692 - val_loss: 0.7835\n",
      "Epoch 38/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2648 - val_accuracy: 0.6540 - val_loss: 0.8419\n",
      "Epoch 39/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2561 - val_accuracy: 0.6707 - val_loss: 0.8256\n",
      "Epoch 40/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.2373 - val_accuracy: 0.6524 - val_loss: 0.8642\n",
      "Epoch 41/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2409 - val_accuracy: 0.6402 - val_loss: 0.8480\n",
      "Epoch 42/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2217 - val_accuracy: 0.6494 - val_loss: 0.8547\n",
      "Epoch 43/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.1973 - val_accuracy: 0.6570 - val_loss: 0.9101\n",
      "Epoch 44/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2111 - val_accuracy: 0.6540 - val_loss: 0.8761\n",
      "Epoch 45/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.1821 - val_accuracy: 0.6357 - val_loss: 0.9252\n",
      "Epoch 46/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1811 - val_accuracy: 0.6494 - val_loss: 0.8971\n",
      "Epoch 47/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.1701 - val_accuracy: 0.6555 - val_loss: 0.8977\n",
      "Epoch 48/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.1858 - val_accuracy: 0.6448 - val_loss: 0.9834\n",
      "Epoch 49/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1726 - val_accuracy: 0.6540 - val_loss: 1.0498\n",
      "Epoch 50/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.1648 - val_accuracy: 0.6433 - val_loss: 1.0127\n",
      "Epoch 51/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1452 - val_accuracy: 0.6463 - val_loss: 0.9900\n",
      "Epoch 52/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.1312 - val_accuracy: 0.6601 - val_loss: 1.0106\n",
      "Epoch 53/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.1330 - val_accuracy: 0.6570 - val_loss: 0.9908\n",
      "Epoch 54/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.1243 - val_accuracy: 0.6616 - val_loss: 1.0174\n",
      "Epoch 55/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.1264 - val_accuracy: 0.6616 - val_loss: 1.0613\n",
      "Epoch 56/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.1130 - val_accuracy: 0.6448 - val_loss: 1.1296\n",
      "Epoch 57/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.1204 - val_accuracy: 0.6402 - val_loss: 1.1632\n",
      "Epoch 58/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.1094 - val_accuracy: 0.6448 - val_loss: 1.1285\n",
      "Epoch 59/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0982 - val_accuracy: 0.6646 - val_loss: 1.1641\n",
      "Epoch 60/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0997 - val_accuracy: 0.6463 - val_loss: 1.1067\n",
      "Epoch 61/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0920 - val_accuracy: 0.6372 - val_loss: 1.1513\n",
      "Epoch 62/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0896 - val_accuracy: 0.6646 - val_loss: 1.1633\n",
      "Epoch 63/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0831 - val_accuracy: 0.6555 - val_loss: 1.2154\n",
      "Epoch 64/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0793 - val_accuracy: 0.6326 - val_loss: 1.2112\n",
      "Epoch 65/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0780 - val_accuracy: 0.6418 - val_loss: 1.2288\n",
      "Epoch 66/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0717 - val_accuracy: 0.6357 - val_loss: 1.3230\n",
      "Epoch 67/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0727 - val_accuracy: 0.6433 - val_loss: 1.2061\n",
      "Epoch 68/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0721 - val_accuracy: 0.6524 - val_loss: 1.3424\n",
      "Epoch 69/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0756 - val_accuracy: 0.6433 - val_loss: 1.3504\n",
      "Epoch 70/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0629 - val_accuracy: 0.6570 - val_loss: 1.3181\n",
      "Epoch 71/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0609 - val_accuracy: 0.6265 - val_loss: 1.3454\n",
      "Epoch 72/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0678 - val_accuracy: 0.6509 - val_loss: 1.3490\n",
      "Epoch 73/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0482 - val_accuracy: 0.6585 - val_loss: 1.4239\n",
      "Epoch 74/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0450 - val_accuracy: 0.6585 - val_loss: 1.4085\n",
      "Epoch 75/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0418 - val_accuracy: 0.6357 - val_loss: 1.4609\n",
      "Epoch 76/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0419 - val_accuracy: 0.6540 - val_loss: 1.4024\n",
      "Epoch 77/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0433 - val_accuracy: 0.6418 - val_loss: 1.5314\n",
      "Epoch 78/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0487 - val_accuracy: 0.6372 - val_loss: 1.5238\n",
      "Epoch 79/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0508 - val_accuracy: 0.6357 - val_loss: 1.5191\n",
      "Epoch 80/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0414 - val_accuracy: 0.6341 - val_loss: 1.5926\n",
      "Epoch 81/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0623 - val_accuracy: 0.6479 - val_loss: 1.5654\n",
      "Epoch 82/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.0909 - val_accuracy: 0.6494 - val_loss: 1.5632\n",
      "Epoch 83/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0558 - val_accuracy: 0.6402 - val_loss: 1.5265\n",
      "Epoch 84/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0354 - val_accuracy: 0.6479 - val_loss: 1.6105\n",
      "Epoch 85/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0349 - val_accuracy: 0.6433 - val_loss: 1.5974\n",
      "Epoch 86/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0281 - val_accuracy: 0.6494 - val_loss: 1.6162\n",
      "Epoch 87/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0305 - val_accuracy: 0.6524 - val_loss: 1.6055\n",
      "Epoch 88/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.6494 - val_loss: 1.6071\n",
      "Epoch 89/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.6524 - val_loss: 1.6033\n",
      "Epoch 90/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0210 - val_accuracy: 0.6479 - val_loss: 1.7755\n",
      "Epoch 91/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.6509 - val_loss: 1.6446\n",
      "Epoch 92/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.6479 - val_loss: 1.6853\n",
      "Epoch 93/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0146 - val_accuracy: 0.6448 - val_loss: 1.6850\n",
      "Epoch 94/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.6479 - val_loss: 1.7582\n",
      "Epoch 95/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.6311 - val_loss: 1.7581\n",
      "Epoch 96/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.6402 - val_loss: 1.7428\n",
      "Epoch 97/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0179 - val_accuracy: 0.6509 - val_loss: 1.7309\n",
      "Epoch 98/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.6402 - val_loss: 1.7831\n",
      "Epoch 99/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.6250 - val_loss: 1.8432\n",
      "Epoch 100/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.6387 - val_loss: 1.8162\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = unregularized_model.fit(X_train, Y_train, epochs = 100, validation_data=(X_val, Y_val))\n",
    "\n",
    "# plot training vs Validation loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a regularized model that uses L2 Regularization and train the model with X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5477 - loss: 0.7206 - val_accuracy: 0.5507 - val_loss: 0.7222\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5995 - loss: 0.6958 - val_accuracy: 0.5983 - val_loss: 0.7032\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.6935 - val_accuracy: 0.5702 - val_loss: 0.7053\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6021 - loss: 0.6789 - val_accuracy: 0.5714 - val_loss: 0.7262\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 0.6855 - val_accuracy: 0.5946 - val_loss: 0.7011\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6438 - loss: 0.6634 - val_accuracy: 0.6142 - val_loss: 0.6831\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6485 - loss: 0.6601 - val_accuracy: 0.6105 - val_loss: 0.6787\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6655 - loss: 0.6380 - val_accuracy: 0.6227 - val_loss: 0.6786\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6221 - loss: 0.6540 - val_accuracy: 0.6447 - val_loss: 0.6590\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6702 - loss: 0.6313 - val_accuracy: 0.6569 - val_loss: 0.6447\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.6110 - val_accuracy: 0.6545 - val_loss: 0.6441\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6977 - loss: 0.5997 - val_accuracy: 0.6569 - val_loss: 0.6466\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6791 - loss: 0.6138 - val_accuracy: 0.6545 - val_loss: 0.6340\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 0.5991 - val_accuracy: 0.6532 - val_loss: 0.6424\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.6058 - val_accuracy: 0.6484 - val_loss: 0.6466\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.5854 - val_accuracy: 0.6545 - val_loss: 0.6428\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.5828 - val_accuracy: 0.6667 - val_loss: 0.6346\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.5974 - val_accuracy: 0.6557 - val_loss: 0.6413\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.5776 - val_accuracy: 0.6667 - val_loss: 0.6291\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.5979 - val_accuracy: 0.6606 - val_loss: 0.6357\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.5882 - val_accuracy: 0.6606 - val_loss: 0.6322\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.5738 - val_accuracy: 0.6691 - val_loss: 0.6283\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7068 - loss: 0.5789 - val_accuracy: 0.6691 - val_loss: 0.6369\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.5776 - val_accuracy: 0.6654 - val_loss: 0.6281\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.5739 - val_accuracy: 0.6667 - val_loss: 0.6293\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.5671 - val_accuracy: 0.6679 - val_loss: 0.6397\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5553 - val_accuracy: 0.6532 - val_loss: 0.6564\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7268 - loss: 0.5552 - val_accuracy: 0.6630 - val_loss: 0.6341\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5616 - val_accuracy: 0.6667 - val_loss: 0.6323\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5600 - val_accuracy: 0.6606 - val_loss: 0.6436\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.5509 - val_accuracy: 0.6581 - val_loss: 0.6741\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.5511 - val_accuracy: 0.6569 - val_loss: 0.6418\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5616 - val_accuracy: 0.6557 - val_loss: 0.6498\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7320 - loss: 0.5424 - val_accuracy: 0.6642 - val_loss: 0.6460\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5432 - val_accuracy: 0.6557 - val_loss: 0.6482\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7534 - loss: 0.5312 - val_accuracy: 0.6508 - val_loss: 0.6481\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5446 - val_accuracy: 0.6569 - val_loss: 0.6579\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5382 - val_accuracy: 0.6520 - val_loss: 0.6578\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7468 - loss: 0.5328 - val_accuracy: 0.6557 - val_loss: 0.6652\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5362 - val_accuracy: 0.6459 - val_loss: 0.6681\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.5279 - val_accuracy: 0.6557 - val_loss: 0.6571\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7494 - loss: 0.5298 - val_accuracy: 0.6532 - val_loss: 0.6595\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7461 - loss: 0.5239 - val_accuracy: 0.6606 - val_loss: 0.6824\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7541 - loss: 0.5271 - val_accuracy: 0.6459 - val_loss: 0.6747\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.5234 - val_accuracy: 0.6484 - val_loss: 0.6697\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.5189 - val_accuracy: 0.6545 - val_loss: 0.6797\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.4983 - val_accuracy: 0.6410 - val_loss: 0.6711\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.4980 - val_accuracy: 0.6386 - val_loss: 0.6756\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.4965 - val_accuracy: 0.6374 - val_loss: 0.6835\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4778 - val_accuracy: 0.6484 - val_loss: 0.6872\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4874 - val_accuracy: 0.6386 - val_loss: 0.6849\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.4838 - val_accuracy: 0.6349 - val_loss: 0.6888\n",
      "Epoch 53/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.4965 - val_accuracy: 0.6325 - val_loss: 0.6985\n",
      "Epoch 54/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.4947 - val_accuracy: 0.6337 - val_loss: 0.7022\n",
      "Epoch 55/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8087 - loss: 0.4609 - val_accuracy: 0.6471 - val_loss: 0.6944\n",
      "Epoch 56/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7895 - loss: 0.4804 - val_accuracy: 0.6410 - val_loss: 0.7071\n",
      "Epoch 57/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8039 - loss: 0.4645 - val_accuracy: 0.6300 - val_loss: 0.7025\n",
      "Epoch 58/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.4710 - val_accuracy: 0.6361 - val_loss: 0.7028\n",
      "Epoch 59/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7896 - loss: 0.4701 - val_accuracy: 0.6471 - val_loss: 0.7218\n",
      "Epoch 60/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4717 - val_accuracy: 0.6374 - val_loss: 0.7239\n",
      "Epoch 61/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.4467 - val_accuracy: 0.6496 - val_loss: 0.7207\n",
      "Epoch 62/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.4511 - val_accuracy: 0.6313 - val_loss: 0.7212\n",
      "Epoch 63/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.4478 - val_accuracy: 0.6313 - val_loss: 0.7183\n",
      "Epoch 64/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8244 - loss: 0.4400 - val_accuracy: 0.6361 - val_loss: 0.7523\n",
      "Epoch 65/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.4347 - val_accuracy: 0.6300 - val_loss: 0.7549\n",
      "Epoch 66/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4535 - val_accuracy: 0.6422 - val_loss: 0.7380\n",
      "Epoch 67/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.4471 - val_accuracy: 0.6484 - val_loss: 0.7398\n",
      "Epoch 68/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8302 - loss: 0.4288 - val_accuracy: 0.6410 - val_loss: 0.7490\n",
      "Epoch 69/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.4418 - val_accuracy: 0.6398 - val_loss: 0.7446\n",
      "Epoch 70/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.4214 - val_accuracy: 0.6349 - val_loss: 0.7538\n",
      "Epoch 71/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4222 - val_accuracy: 0.6435 - val_loss: 0.7586\n",
      "Epoch 72/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.4296 - val_accuracy: 0.6459 - val_loss: 0.7630\n",
      "Epoch 73/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4158 - val_accuracy: 0.6313 - val_loss: 0.7688\n",
      "Epoch 74/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3994 - val_accuracy: 0.6484 - val_loss: 0.7754\n",
      "Epoch 75/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3910 - val_accuracy: 0.6435 - val_loss: 0.7633\n",
      "Epoch 76/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.4108 - val_accuracy: 0.6361 - val_loss: 0.7660\n",
      "Epoch 77/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.3759 - val_accuracy: 0.6227 - val_loss: 0.7736\n",
      "Epoch 78/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.3891 - val_accuracy: 0.6276 - val_loss: 0.7782\n",
      "Epoch 79/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8387 - loss: 0.3932 - val_accuracy: 0.6154 - val_loss: 0.7766\n",
      "Epoch 80/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.3870 - val_accuracy: 0.6337 - val_loss: 0.7796\n",
      "Epoch 81/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3767 - val_accuracy: 0.6313 - val_loss: 0.7918\n",
      "Epoch 82/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3689 - val_accuracy: 0.6288 - val_loss: 0.7938\n",
      "Epoch 83/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3682 - val_accuracy: 0.6178 - val_loss: 0.8081\n",
      "Epoch 84/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8489 - loss: 0.3814 - val_accuracy: 0.6239 - val_loss: 0.8020\n",
      "Epoch 85/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.3788 - val_accuracy: 0.6361 - val_loss: 0.8176\n",
      "Epoch 86/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3628 - val_accuracy: 0.6349 - val_loss: 0.8034\n",
      "Epoch 87/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3634 - val_accuracy: 0.6374 - val_loss: 0.8255\n",
      "Epoch 88/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3589 - val_accuracy: 0.6300 - val_loss: 0.8230\n",
      "Epoch 89/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3639 - val_accuracy: 0.6398 - val_loss: 0.8285\n",
      "Epoch 90/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3672 - val_accuracy: 0.6410 - val_loss: 0.8213\n",
      "Epoch 91/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.3432 - val_accuracy: 0.6398 - val_loss: 0.8407\n",
      "Epoch 92/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8739 - loss: 0.3498 - val_accuracy: 0.6276 - val_loss: 0.8552\n",
      "Epoch 93/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.3438 - val_accuracy: 0.6459 - val_loss: 0.8311\n",
      "Epoch 94/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.3352 - val_accuracy: 0.6435 - val_loss: 0.8620\n",
      "Epoch 95/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8756 - loss: 0.3454 - val_accuracy: 0.6374 - val_loss: 0.8465\n",
      "Epoch 96/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.3365 - val_accuracy: 0.6422 - val_loss: 0.8515\n",
      "Epoch 97/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.3287 - val_accuracy: 0.6374 - val_loss: 0.8639\n",
      "Epoch 98/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 0.3277 - val_accuracy: 0.6386 - val_loss: 0.8751\n",
      "Epoch 99/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.3236 - val_accuracy: 0.6435 - val_loss: 0.8749\n",
      "Epoch 100/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.3062 - val_accuracy: 0.6337 - val_loss: 0.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14a365dc0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularizer = tf.keras.regularizers.l2(0.0001)\n",
    "reg_model = neural_net(regularizer)\n",
    "\n",
    "reg_model.fit(X_train, Y_train, epochs = 100, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Dropout in confluence with L2 Regularization\n",
    "\n",
    "Our model currently has an accuracy of 89.14% and a loss of 0.34 on the training data and 64.96% accuracy and a loss of 0.86, suggesting a possible case of `Overfitting`. Now let's try to implement early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5386 - loss: 1.3039 - val_accuracy: 0.5800 - val_loss: 1.2656\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5665 - loss: 1.2905 - val_accuracy: 0.5800 - val_loss: 1.2654\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 1.2982 - val_accuracy: 0.5800 - val_loss: 1.2621\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 1.2881 - val_accuracy: 0.5800 - val_loss: 1.2616\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6008 - loss: 1.2624 - val_accuracy: 0.5800 - val_loss: 1.2619\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 1.2683 - val_accuracy: 0.5800 - val_loss: 1.2679\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5735 - loss: 1.2740 - val_accuracy: 0.5800 - val_loss: 1.2598\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6029 - loss: 1.2471 - val_accuracy: 0.5800 - val_loss: 1.2564\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5824 - loss: 1.2638 - val_accuracy: 0.5800 - val_loss: 1.2818\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5760 - loss: 1.2701 - val_accuracy: 0.5800 - val_loss: 1.2961\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 1.2560 - val_accuracy: 0.5800 - val_loss: 1.2678\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5923 - loss: 1.2600 - val_accuracy: 0.5800 - val_loss: 1.2533\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 1.2540 - val_accuracy: 0.5800 - val_loss: 1.2556\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 1.2435 - val_accuracy: 0.5800 - val_loss: 1.2577\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5867 - loss: 1.2553 - val_accuracy: 0.5800 - val_loss: 1.2518\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5746 - loss: 1.2500 - val_accuracy: 0.5800 - val_loss: 1.2548\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6141 - loss: 1.2358 - val_accuracy: 0.5800 - val_loss: 1.2601\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 1.2472 - val_accuracy: 0.5800 - val_loss: 1.2519\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5879 - loss: 1.2512 - val_accuracy: 0.5800 - val_loss: 1.2491\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6150 - loss: 1.2421 - val_accuracy: 0.5800 - val_loss: 1.2444\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5850 - loss: 1.2515 - val_accuracy: 0.5800 - val_loss: 1.2478\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 1.2461 - val_accuracy: 0.5800 - val_loss: 1.2427\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6072 - loss: 1.2443 - val_accuracy: 0.5800 - val_loss: 1.2468\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5911 - loss: 1.2377 - val_accuracy: 0.5800 - val_loss: 1.2428\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 1.2382 - val_accuracy: 0.5800 - val_loss: 1.2444\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 1.2339 - val_accuracy: 0.5800 - val_loss: 1.2385\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6153 - loss: 1.2286 - val_accuracy: 0.5800 - val_loss: 1.2448\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6167 - loss: 1.2300 - val_accuracy: 0.5800 - val_loss: 1.2369\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6215 - loss: 1.2271 - val_accuracy: 0.5800 - val_loss: 1.2435\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6167 - loss: 1.2257 - val_accuracy: 0.5800 - val_loss: 1.2354\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5990 - loss: 1.2354 - val_accuracy: 0.5800 - val_loss: 1.2344\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 1.2141 - val_accuracy: 0.5800 - val_loss: 1.2420\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6229 - loss: 1.2176 - val_accuracy: 0.5800 - val_loss: 1.2327\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 1.2324 - val_accuracy: 0.5800 - val_loss: 1.2322\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 1.2222 - val_accuracy: 0.5800 - val_loss: 1.2299\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 1.2244 - val_accuracy: 0.5800 - val_loss: 1.2328\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6152 - loss: 1.2226 - val_accuracy: 0.5800 - val_loss: 1.2279\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6163 - loss: 1.2183 - val_accuracy: 0.5800 - val_loss: 1.2300\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6367 - loss: 1.2068 - val_accuracy: 0.5800 - val_loss: 1.2306\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6029 - loss: 1.2226 - val_accuracy: 0.5800 - val_loss: 1.2261\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 1.2073 - val_accuracy: 0.5800 - val_loss: 1.2267\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6226 - loss: 1.2095 - val_accuracy: 0.5800 - val_loss: 1.2300\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6118 - loss: 1.2160 - val_accuracy: 0.5800 - val_loss: 1.2554\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6194 - loss: 1.2102 - val_accuracy: 0.5800 - val_loss: 1.2215\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6261 - loss: 1.2041 - val_accuracy: 0.5800 - val_loss: 1.2204\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6277 - loss: 1.2044 - val_accuracy: 0.5800 - val_loss: 1.2194\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6070 - loss: 1.2197 - val_accuracy: 0.5800 - val_loss: 1.2306\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6096 - loss: 1.2112 - val_accuracy: 0.5800 - val_loss: 1.2232\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 1.2099 - val_accuracy: 0.5800 - val_loss: 1.2292\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6530 - loss: 1.1867 - val_accuracy: 0.5800 - val_loss: 1.2160\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6213 - loss: 1.2006 - val_accuracy: 0.5800 - val_loss: 1.2143\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6258 - loss: 1.1978 - val_accuracy: 0.5800 - val_loss: 1.2199\n",
      "Epoch 53/100\n",
      "\u001b[1m26/77\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6458 - loss: 1.1917 "
     ]
    }
   ],
   "source": [
    "# Define the neural network model with L2 regularization and Dropout\n",
    "def neural_net_with_dropout(regularizer=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(9,)),\n",
    "        tf.keras.layers.Dense(500, activation=\"sigmoid\", kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(250, activation=\"sigmoid\", kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "    ])\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer='SGD',\n",
    "                  loss=loss_function,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "regularizer = tf.keras.regularizers.l(0.0001)\n",
    "dropout_model = neural_net_with_dropout(regularizer)\n",
    "\n",
    "# Train the model with the EarlyStopping callback\n",
    "dropout_model.fit(\n",
    "    X_train, Y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_val, Y_val)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
